{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP).\n",
    "\n",
    "Ref: => https://www.ibm.com/topics/stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other Words, \n",
    "Stemming in Natural Language Processing (NLP) is the process of reducing a word to its base or root form by removing prefixes, suffixes, or inflections. The goal of stemming is to simplify words for text processing by reducing different forms of a word to a common base form. This is particularly useful in search engines, information retrieval, and text mining to group similar words together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:\n",
    "\"running\", \"runner\", and \"ran\" can all be reduced to the stem \"run\".\n",
    "\"better\" and \"best\" might both be reduced to \"bet\" (although this is an oversimplification of meaning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=== Importance of Stemming: ===\n",
    "\n",
    "Helps to normalize text data by reducing words to their root form.\n",
    "\n",
    "Reduces the complexity of language in text data.\n",
    "\n",
    "Can improve search engine performance by allowing different forms of a word to match the same search query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===  Common Stemming Algorithms: ====\n",
    "\n",
    "Porter Stemmer: One of the most widely used stemming algorithms. It follows a set of rules to remove common suffixes.\n",
    "\n",
    "Lancaster Stemmer: A more aggressive algorithm that tends to reduce words to shorter stems.\n",
    "    \n",
    "Snowball Stemmer: An improved version of the Porter Stemmer, providing better language support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification Problem\n",
    "## Comments of product is a positive review or negative review\n",
    "## Reviews----> eating, eat,eaten [going,gone,goes]--->go\n",
    "\n",
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PorterStemmer\n",
    " The Porter Stemmer is one of the most commonly used stemming algorithms in Natural Language Processing (NLP). It was introduced by Martin Porter in 1980, and it is designed to reduce words to their base or root form (known as the \"stem\") by systematically removing common suffixes from English words. The algorithm applies a series of transformation rules to words, which allows different forms of the same word to be treated as identical in various NLP tasks like search engines, text mining, and information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---->eat\n",
      "eats ---->eat\n",
      "eaten ---->eaten\n",
      "writing ---->write\n",
      "writes ---->write\n",
      "programming ---->program\n",
      "programs ---->program\n",
      "history ---->histori\n",
      "finally ---->final\n",
      "finalized ---->final\n",
      "porter_stemmed: ['eat', 'eat', 'eaten', 'write', 'write', 'program', 'program', 'histori', 'final', 'final']\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\" ---->\"+stemming.stem(word))\n",
    "    \n",
    "# another way list comprehension \n",
    "porter_stemmed = [stemming.stem(word) for word in words]\n",
    "print(f\"porter_stemmed:\", porter_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations') # dis advantage of PorterStemmer/ steamming , this solve by lematization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"sitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegexpStemmer class\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowball Stemmer\n",
    " It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer.\n",
    "\n",
    " Improved Accuracy: Snowball Stemmer fixes some of the aggressive reductions of Porter Stemmer, providing better word stems that are closer to actual root words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballsstemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eaten\n",
      "writing---->write\n",
      "writes---->write\n",
      "programming---->program\n",
      "programs---->program\n",
      "history---->histori\n",
      "finally---->final\n",
      "finalized---->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+snowballsstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballsstemmer.stem(\"fairly\"),snowballsstemmer.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballsstemmer.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To over come the situation of stemming disadvantages we go through Lematization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While stemming is a useful technique in Natural Language Processing (NLP) to reduce words to their base forms, it has several disadvantages and limitations:\n",
    "\n",
    "1. Over-stemming:\n",
    "Stemming can be too aggressive, reducing words to stems that are not linguistically meaningful or related to the original word.\n",
    "For example, the word \"universe\" might be reduced to \"univers\", which doesn't carry the full meaning of the original word.\n",
    "Over-stemming can lead to false positives, where different words with distinct meanings are treated as the same.\n",
    "Example:\n",
    "\n",
    "Words like \"universal\" and \"university\" might be stemmed to the same root \"univers\", though they have different meanings.\n",
    "2. Under-stemming:\n",
    "Sometimes stemming algorithms fail to reduce words to their true root form, leaving words partially stemmed.\n",
    "This results in missed matches between words that should be considered equivalent in meaning.\n",
    "Example:\n",
    "\n",
    "The words \"ran\" and \"running\" might not be reduced to the same root, missing the fact that both relate to \"run.\"\n",
    "3. Loss of Semantics:\n",
    "Stemming focuses purely on the form of the word and ignores its context or meaning.\n",
    "By stripping suffixes and prefixes, the algorithm often loses the semantic information that may be important for understanding the full context of the word.\n",
    "Example:\n",
    "\n",
    "Words like \"better\" and \"good\" are related in meaning but have very different stems, so stemming won't help recognize their synonymy.\n",
    "4. Language-Specific Limitations:\n",
    "Stemming algorithms, such as Porter Stemmer, are typically designed for specific languages (like English), and may not work well for other languages with different morphological rules.\n",
    "Even though Snowball Stemmer supports multiple languages, it still might not capture all linguistic nuances for highly inflected languages like Finnish or Turkish.\n",
    "5. Inconsistent Results:\n",
    "Different stemming algorithms can produce inconsistent results for the same word. For example, the Porter Stemmer might stem \"connection\" to \"connect\", while another algorithm might reduce it to \"conn\".\n",
    "This inconsistency can make the output difficult to interpret and apply in some NLP tasks.\n",
    "6. Non-Words as Stems:\n",
    "Stemming can often produce stems that are not valid words in the language, making it harder to interpret or use these stems in a human-readable context.\n",
    "Example:\n",
    "\n",
    "The word \"agreement\" might be stemmed to \"agre\", which is not a meaningful word in English.\n",
    "7. Lack of Handling of Compound Words:\n",
    "Stemming algorithms are generally not well-suited to handle compound words or multi-word expressions.\n",
    "They treat compound words as separate tokens and may produce inaccurate stems for each part.\n",
    "Example:\n",
    "\n",
    "The word \"notebook\" may be incorrectly split and stemmed as \"note\" and \"book\", losing the combined meaning.\n",
    "8. Not Suitable for Complex NLP Tasks:\n",
    "Stemming is typically used for basic text normalization tasks, such as search engines or information retrieval.\n",
    "For more complex NLP tasks, like machine translation, sentiment analysis, or language understanding, stemming can be too simplistic and may lead to poor performance.\n",
    "9. Alternative Techniques (e.g., Lemmatization):\n",
    "Lemmatization, which reduces words to their dictionary or canonical form, is often preferred over stemming for more advanced NLP tasks.\n",
    "Lemmatization considers the part of speech and context of the word, providing more accurate root forms than stemming.\n",
    "Example:\n",
    "\n",
    "Lemmatization would reduce \"better\" to \"good\" (depending on context), while stemming would not make this connection.\n",
    "Summary of Stemming Disadvantages:\n",
    "Disadvantage\tDescription\n",
    "Over-stemming\tStems too aggressively, leading to loss of meaning.\n",
    "Under-stemming\tFails to reduce words to their correct root form.\n",
    "Loss of Semantics\tIgnores the meaning and context of the word, leading to ambiguity.\n",
    "Language-Specific Issues\tOften designed for specific languages, lacking flexibility.\n",
    "Inconsistent Results\tDifferent stemming algorithms produce varying outputs.\n",
    "Non-Words as Stems\tProduces stems that are not valid or recognizable words.\n",
    "Handling Compound Words\tStruggles with compound words and multi-word expressions.\n",
    "Limited NLP Use\tNot ideal for complex NLP tasks like translation or sentiment analysis.\n",
    "Better Alternatives\tLemmatization often provides better results in many scenarios.\n",
    "In many cases, lemmatization is preferred over stemming because it is more context-aware and produces more accurate root forms of words. However, stemming is still useful for quick and computationally inexpensive text preprocessing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
